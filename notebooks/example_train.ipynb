{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AKI Prediction - Training Example\n",
        "\n",
        "This notebook demonstrates how to use the modular AKI prediction package to:\n",
        "1. Load and preprocess data\n",
        "2. Train multiple models with hyperparameter tuning\n",
        "3. Evaluate models and save the best one\n",
        "4. Generate SHAP explanations\n",
        "\n",
        "## Simple Usage Example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the package\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "from src import (\n",
        "    setup_plotting, load_vitaldb_data, preprocess_data, prepare_train_test_data,\n",
        "    get_default_model_configs, hyperparameter_tuning, save_best_model,\n",
        "    evaluate_models, print_evaluation_summary,\n",
        "    plot_roc_curves, plot_pr_curves, plot_model_comparison, plot_confusion_matrices,\n",
        "    explain_model_with_shap, analyze_logistic_regression_coefficients\n",
        ")\n",
        "\n",
        "# Setup plotting\n",
        "setup_plotting()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "df = load_vitaldb_data()\n",
        "X, y, feature_names = preprocess_data(df)\n",
        "data_dict = prepare_train_test_data(X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Training with Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get model configurations and train models\n",
        "models_config = get_default_model_configs()\n",
        "\n",
        "# Train models with hyperparameter tuning\n",
        "tuned_models = hyperparameter_tuning(\n",
        "    models_config, \n",
        "    data_dict['X_train_dict'], \n",
        "    data_dict['y_train']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model data mapping for evaluation\n",
        "model_data_mapping = {\n",
        "    'LogisticRegression': 'scaled',\n",
        "    'RandomForest': 'imputed',\n",
        "    'XGBoost': 'imputed',\n",
        "    'SVM': 'scaled'\n",
        "}\n",
        "\n",
        "# Evaluate all models\n",
        "results_df = evaluate_models(\n",
        "    tuned_models, \n",
        "    data_dict['X_test_dict'], \n",
        "    data_dict['y_test'], \n",
        "    model_data_mapping\n",
        ")\n",
        "\n",
        "# Print summary\n",
        "print_evaluation_summary(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Save Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find and save the best model\n",
        "best_model_name, best_model = save_best_model(\n",
        "    tuned_models,\n",
        "    data_dict['X_test_dict'],\n",
        "    data_dict['y_test'],\n",
        "    model_data_mapping\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. SHAP Explanations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate SHAP explanations for the best model\n",
        "if 'LogisticRegression' in tuned_models:\n",
        "    lr_model = tuned_models['LogisticRegression']\n",
        "    # Analyze coefficients first\n",
        "    analyze_logistic_regression_coefficients(lr_model, feature_names)\n",
        "    # Generate SHAP explanation\n",
        "    explain_model_with_shap(\n",
        "        lr_model, \n",
        "        data_dict['X_test_dict']['scaled'], \n",
        "        feature_names, \n",
        "        'LogisticRegression', \n",
        "        max_display=15\n",
        "    )\n",
        "\n",
        "# Generate SHAP explanation for XGBoost\n",
        "if 'XGBoost' in tuned_models:\n",
        "    xgb_model = tuned_models['XGBoost']\n",
        "    explain_model_with_shap(\n",
        "        xgb_model, \n",
        "        data_dict['X_test_dict']['imputed'], \n",
        "        feature_names, \n",
        "        'XGBoost', \n",
        "        max_display=15\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
