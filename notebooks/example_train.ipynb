{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AKI Prediction - Training Example\n",
        "\n",
        "This notebook demonstrates how to use the modular AKI prediction package to:\n",
        "1. Load and preprocess data\n",
        "2. Train multiple models with hyperparameter tuning\n",
        "3. Evaluate models and save the best one\n",
        "4. Generate SHAP explanations\n",
        "\n",
        "## Simple Usage Example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the package\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath('../src'))\n",
        "\n",
        "# Import all functions from the package\n",
        "from utils import (\n",
        "    setup_plotting, load_vitaldb_data, preprocess_data, prepare_train_test_data\n",
        ")\n",
        "from train import (\n",
        "    get_default_model_configs, hyperparameter_tuning, save_best_model\n",
        ")\n",
        "from evaluate import (\n",
        "    evaluate_models, print_evaluation_summary\n",
        ")\n",
        "from visualization import (\n",
        "    plot_roc_curves, plot_pr_curves, plot_model_comparison, plot_confusion_matrices\n",
        ")\n",
        "from shap_explainer import (\n",
        "    explain_model_with_shap, analyze_logistic_regression_coefficients\n",
        ")\n",
        "\n",
        "# Setup plotting\n",
        "setup_plotting()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Loading VitalDB dataset...\n",
            "âœ… Dataset loaded: 3989 records\n",
            "ðŸ“Š Features available: 75\n",
            "ðŸ”§ Preprocessing data...\n",
            "âœ… Data preprocessing completed\n",
            "ðŸ“Š Final dataset shape: (3989, 43)\n",
            "ðŸŽ¯ Target distribution: 210/3989 positive cases (5.26%)\n",
            "ðŸ”§ Preparing train/test data...\n",
            "ðŸ“Š Training set: (3191, 43)\n",
            "ðŸ“Š Test set: (798, 43)\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "df = load_vitaldb_data()\n",
        "X, y, feature_names = preprocess_data(df)\n",
        "data_dict = prepare_train_test_data(X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Training with Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get model configurations and train models\n",
        "models_config = get_default_model_configs()\n",
        "\n",
        "# Train models with hyperparameter tuning\n",
        "tuned_models = hyperparameter_tuning(\n",
        "    models_config, \n",
        "    data_dict['X_train_dict'], \n",
        "    data_dict['y_train']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model data mapping for evaluation\n",
        "model_data_mapping = {\n",
        "    'LogisticRegression': 'scaled',\n",
        "    'RandomForest': 'imputed',\n",
        "    'XGBoost': 'imputed',\n",
        "    'SVM': 'scaled'\n",
        "}\n",
        "\n",
        "# Evaluate all models\n",
        "results_df = evaluate_models(\n",
        "    tuned_models, \n",
        "    data_dict['X_test_dict'], \n",
        "    data_dict['y_test'], \n",
        "    model_data_mapping\n",
        ")\n",
        "\n",
        "# Print summary\n",
        "print_evaluation_summary(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Save Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find and save the best model\n",
        "best_model_name, best_model = save_best_model(\n",
        "    tuned_models,\n",
        "    data_dict['X_test_dict'],\n",
        "    data_dict['y_test'],\n",
        "    model_data_mapping\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. SHAP Explanations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate SHAP explanations for the best model\n",
        "if 'LogisticRegression' in tuned_models:\n",
        "    lr_model = tuned_models['LogisticRegression']\n",
        "    # Analyze coefficients first\n",
        "    analyze_logistic_regression_coefficients(lr_model, feature_names)\n",
        "    # Generate SHAP explanation\n",
        "    explain_model_with_shap(\n",
        "        lr_model, \n",
        "        data_dict['X_test_dict']['scaled'], \n",
        "        feature_names, \n",
        "        'LogisticRegression', \n",
        "        max_display=15\n",
        "    )\n",
        "\n",
        "# Generate SHAP explanation for XGBoost\n",
        "if 'XGBoost' in tuned_models:\n",
        "    xgb_model = tuned_models['XGBoost']\n",
        "    explain_model_with_shap(\n",
        "        xgb_model, \n",
        "        data_dict['X_test_dict']['imputed'], \n",
        "        feature_names, \n",
        "        'XGBoost', \n",
        "        max_display=15\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ehr-datasets",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
