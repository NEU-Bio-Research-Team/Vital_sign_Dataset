{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AKI Prediction - Training Example\n",
        "\n",
        "This notebook demonstrates how to use the modular AKI prediction package to:\n",
        "1. Load and preprocess data\n",
        "2. Train multiple models with hyperparameter tuning\n",
        "3. Evaluate models and save the best one\n",
        "4. Generate SHAP explanations\n",
        "\n",
        "## Simple Usage Example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'src'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../src\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     setup_plotting, load_vitaldb_data, preprocess_data, prepare_train_test_data,\n\u001b[1;32m      7\u001b[0m     get_default_model_configs, hyperparameter_tuning, save_best_model,\n\u001b[1;32m      8\u001b[0m     evaluate_models, print_evaluation_summary,\n\u001b[1;32m      9\u001b[0m     plot_roc_curves, plot_pr_curves, plot_model_comparison, plot_confusion_matrices,\n\u001b[1;32m     10\u001b[0m     explain_model_with_shap, analyze_logistic_regression_coefficients\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Setup plotting\u001b[39;00m\n\u001b[1;32m     14\u001b[0m setup_plotting()\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
          ]
        }
      ],
      "source": [
        "# Import the package\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath('../src'))\n",
        "\n",
        "# Import all functions from the package\n",
        "from utils import (\n",
        "    setup_plotting, load_vitaldb_data, preprocess_data, prepare_train_test_data\n",
        ")\n",
        "from train import (\n",
        "    get_default_model_configs, hyperparameter_tuning, save_best_model\n",
        ")\n",
        "from evaluate import (\n",
        "    evaluate_models, print_evaluation_summary\n",
        ")\n",
        "from visualization import (\n",
        "    plot_roc_curves, plot_pr_curves, plot_model_comparison, plot_confusion_matrices\n",
        ")\n",
        "from shap_explainer import (\n",
        "    explain_model_with_shap, analyze_logistic_regression_coefficients\n",
        ")\n",
        "\n",
        "# Setup plotting\n",
        "setup_plotting()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "df = load_vitaldb_data()\n",
        "X, y, feature_names = preprocess_data(df)\n",
        "data_dict = prepare_train_test_data(X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Training with Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get model configurations and train models\n",
        "models_config = get_default_model_configs()\n",
        "\n",
        "# Train models with hyperparameter tuning\n",
        "tuned_models = hyperparameter_tuning(\n",
        "    models_config, \n",
        "    data_dict['X_train_dict'], \n",
        "    data_dict['y_train']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model data mapping for evaluation\n",
        "model_data_mapping = {\n",
        "    'LogisticRegression': 'scaled',\n",
        "    'RandomForest': 'imputed',\n",
        "    'XGBoost': 'imputed',\n",
        "    'SVM': 'scaled'\n",
        "}\n",
        "\n",
        "# Evaluate all models\n",
        "results_df = evaluate_models(\n",
        "    tuned_models, \n",
        "    data_dict['X_test_dict'], \n",
        "    data_dict['y_test'], \n",
        "    model_data_mapping\n",
        ")\n",
        "\n",
        "# Print summary\n",
        "print_evaluation_summary(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Save Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find and save the best model\n",
        "best_model_name, best_model = save_best_model(\n",
        "    tuned_models,\n",
        "    data_dict['X_test_dict'],\n",
        "    data_dict['y_test'],\n",
        "    model_data_mapping\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. SHAP Explanations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate SHAP explanations for the best model\n",
        "if 'LogisticRegression' in tuned_models:\n",
        "    lr_model = tuned_models['LogisticRegression']\n",
        "    # Analyze coefficients first\n",
        "    analyze_logistic_regression_coefficients(lr_model, feature_names)\n",
        "    # Generate SHAP explanation\n",
        "    explain_model_with_shap(\n",
        "        lr_model, \n",
        "        data_dict['X_test_dict']['scaled'], \n",
        "        feature_names, \n",
        "        'LogisticRegression', \n",
        "        max_display=15\n",
        "    )\n",
        "\n",
        "# Generate SHAP explanation for XGBoost\n",
        "if 'XGBoost' in tuned_models:\n",
        "    xgb_model = tuned_models['XGBoost']\n",
        "    explain_model_with_shap(\n",
        "        xgb_model, \n",
        "        data_dict['X_test_dict']['imputed'], \n",
        "        feature_names, \n",
        "        'XGBoost', \n",
        "        max_display=15\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ehr-datasets",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
